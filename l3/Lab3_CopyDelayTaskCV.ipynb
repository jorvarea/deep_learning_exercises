{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Lab3-CopyDelayTask.ipnyb**\n",
        "\n",
        "This simple provided notebook is as initial code for the task of comparing the capacities of Vanilla-RNN and LSTM networks in a sequence memory tasks.\n",
        "\n",
        "**Lab3 1st task:** understand exactly what this code does (what is the task, and why it make sense to use this task), and then execute it with different parameters in order to extract conclusions of the differences obtained for RNN and LSTM. With the default settings, there is a similar behaviour of both models, and even a worse one from the LSTM, so you task is to look at the learning curves, optimize the parameters and then do a fair comparison of both models.\n",
        "\n",
        "**To be uploaded to the Virtual Campus:** A pdf file with a short explanation of what the code does (no code), explaining the task, together with a description of your experiments with the final parameters used and your conclusions about the behavior of both models. A figure (the same format or similar to the one printed by the code with your results should be included)."
      ],
      "metadata": {
        "id": "Jc-UAdkGVTqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_ZEwPjKgWAG7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ8utywUVLAy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9giyGyZRsC5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "input_size = 5 #vector of inputs\n",
        "hidden_size = 32 #def 32\n",
        "output_size = input_size\n",
        "batch_size = 32 # def 32\n",
        "learning_rate = 0.01 #def 0.01\n",
        "max_epochs = 15 # def 15\n",
        "patience = 3  #def 3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "num_runs = 5  # Number of runs to average per delay def:5\n",
        "\n",
        "# Delay values to test\n",
        "delays = list(range(1, 30 , 4))  #def (1, 30, 4))\n",
        "\n",
        "# Data generation\n",
        "def generate_batch_delay(batch_size, delay, input_size):\n",
        "    seq_len = delay * 2\n",
        "    seq = torch.zeros(batch_size, seq_len, input_size)\n",
        "    seq[:, :delay, :] = (torch.rand(batch_size, delay, input_size) > 0.5).float()\n",
        "    target = torch.zeros_like(seq)\n",
        "    target[:, delay:, :] = seq[:, :delay, :]\n",
        "    return seq.to(device), target.to(device), seq_len\n",
        "\n",
        "# Models\n",
        "class VanillaRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        return self.fc(out)\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        return self.fc(out)\n",
        "\n",
        "# Accuracy calculation\n",
        "def binary_accuracy(output, target):\n",
        "    preds = (torch.sigmoid(output) > 0.5).float()\n",
        "    correct = (preds == target).float()\n",
        "    return correct.mean().item()\n",
        "\n",
        "# Train model for given delay with early stopping\n",
        "def train_for_delay_early_stopping(model, delay):\n",
        "    seq_len = delay * 2\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        for _ in range(100):\n",
        "            seq_in, seq_target, _ = generate_batch_delay(batch_size, delay, input_size)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(seq_in)\n",
        "            loss = criterion(output[:, delay:, :], seq_target[:, delay:, :])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "        train_loss /= 100\n",
        "\n",
        "        # Validation loss\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for _ in range(20):\n",
        "                seq_in, seq_target, _ = generate_batch_delay(batch_size, delay, input_size)\n",
        "                output = model(seq_in)\n",
        "                loss = criterion(output[:, delay:, :], seq_target[:, delay:, :])\n",
        "                val_loss += loss.item()\n",
        "        val_loss /= 20\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "    if best_model_state:\n",
        "        model.load_state_dict(best_model_state)\n",
        "    return model\n",
        "\n",
        "# Evaluate model accuracy for given delay\n",
        "def evaluate_for_delay(model, delay, trials=20):\n",
        "    seq_len = delay * 2\n",
        "    model.eval()\n",
        "    acc = 0\n",
        "    with torch.no_grad():\n",
        "        for _ in range(trials):\n",
        "            seq_in, seq_target, _ = generate_batch_delay(batch_size, delay, input_size)\n",
        "            output = model(seq_in)\n",
        "            acc += binary_accuracy(output[:, delay:, :], seq_target[:, delay:, :])\n",
        "    return acc / trials\n",
        "\n",
        "rnn_accuracies = []\n",
        "lstm_accuracies = []\n",
        "\n",
        "for delay in delays:\n",
        "    print(f\"Evaluating delay {delay} over {num_runs} runs ...\")\n",
        "    rnn_accs = []\n",
        "    lstm_accs = []\n",
        "    for _ in range(num_runs):\n",
        "        rnn = VanillaRNN(input_size, hidden_size, output_size).to(device)\n",
        "        rnn = train_for_delay_early_stopping(rnn, delay)\n",
        "        rnn_accs.append(evaluate_for_delay(rnn, delay))\n",
        "\n",
        "        lstm = LSTMModel(input_size, hidden_size, output_size).to(device)\n",
        "        lstm = train_for_delay_early_stopping(lstm, delay)\n",
        "        lstm_accs.append(evaluate_for_delay(lstm, delay))\n",
        "\n",
        "    rnn_accuracies.append(np.mean(rnn_accs))\n",
        "    lstm_accuracies.append(np.mean(lstm_accs))\n",
        "\n",
        "# Plot accuracy vs delay\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(delays, rnn_accuracies, 'o-', label='Vanilla RNN')\n",
        "plt.plot(delays, lstm_accuracies, 's-', label='LSTM')\n",
        "plt.xlabel('Delay Length')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(f'Copy Delay Task: Accuracy vs Delay Length (averaged over {num_runs} runs)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    }
  ]
}