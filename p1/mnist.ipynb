{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79e8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358f3034",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"Datos de entrenamiento\", x_train.shape)\n",
    "print(\"Datos de test\", x_test.shape)\n",
    "print(\"Primeros dígitos: \", y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1168839",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5343538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2be84cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs: int = 10\n",
    "results: list = []\n",
    "train_times: list = []\n",
    "train_losses: list = []\n",
    "train_accuracies: list = []\n",
    "test_losses: list = []\n",
    "test_accuracies: list = []\n",
    "num_classes: int = 10\n",
    "avg_proba_matrices: dict[str, np.ndarray] = {}\n",
    "\n",
    "for optimizer in ['sgd', 'adagrad', 'rmsprop', 'adam']:\n",
    "    print(f\"Training with {optimizer}\")\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    start_time: float = time.time()\n",
    "    h = model.fit(x_train, y_train, epochs=epochs)\n",
    "    end_time: float = time.time()\n",
    "    elapsed_time: float = end_time - start_time\n",
    "    print(f\"Training time with {optimizer}: {elapsed_time:.2f} seconds\")\n",
    "    train_times.append(elapsed_time)\n",
    "    print(f\"Evaluation in training\")\n",
    "    train_loss, train_accuracy = model.evaluate(x_train, y_train)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    print(f\"Evaluation in test\")\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    results.append(h)\n",
    "    # Average probability matrix on test set (rows=true 0-9, cols=pred 0-9)\n",
    "    probs: np.ndarray = model.predict(x_test, verbose=0)\n",
    "    avg_matrix: np.ndarray = np.zeros((num_classes, num_classes), dtype=np.float64)\n",
    "    for true_label in range(num_classes):\n",
    "        mask: np.ndarray = (y_test == true_label)\n",
    "        if np.any(mask):\n",
    "            avg_matrix[true_label] = probs[mask].mean(axis=0)\n",
    "        else:\n",
    "            avg_matrix[true_label] = 0.0\n",
    "    avg_proba_matrices[optimizer] = avg_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e71b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizers = ['sgd', 'adagrad', 'rmsprop', 'adam']\n",
    "for i, h in enumerate(results):\n",
    "    print(optimizers[i])\n",
    "    print(f\"train_times[i]: {train_times[i]:.2f} seconds\")\n",
    "    print(f\"train_losses[i]: {train_losses[i]:.2f}\")\n",
    "    print(f\"train_accuracies[i]: {train_accuracies[i]:.2f}\")\n",
    "    print(f\"test_losses[i]: {test_losses[i]:.2f}\")\n",
    "    print(f\"test_accuracies[i]: {test_accuracies[i]:.2f}\")\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(h.history['loss'])\n",
    "    plt.title('Pérdida del Modelo')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Época')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(h.history['accuracy'])\n",
    "    plt.title('Precisión del Modelo')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Época')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    M: np.ndarray = avg_proba_matrices[optimizers[i]]\n",
    "    print(\"Matriz de probabilidades promedio (filas=true, columnas=pred):\")\n",
    "    print(np.round(M, 3))\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    im = plt.imshow(M, cmap='viridis', aspect='auto', vmin=0.0, vmax=1.0)\n",
    "    plt.colorbar(im, label='Prob. promedio')\n",
    "    plt.title(f'Matriz de probabilidad promedio - {optimizers[i]}')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Etiqueta verdadera')\n",
    "    plt.xticks(range(num_classes))\n",
    "    plt.yticks(range(num_classes))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
